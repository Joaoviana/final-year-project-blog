# User Evaluation
#### March 16, 2019

### The Experiment
The experiment was divided in three different sections: the first one consisted of introducing the Resonance Audio SDK to the user, by allowing them to listen how a sound source would sound in a room made of, for example, walls made of carpet or marble. In the sound recording, a brief overview is given of the capabilities of developing with RA and A-Frame. In addition, the ‘metal’ and ‘curtain-heavy’ material effect are applied in real-time to the introductory sound file to demonstrate RA’s dynamic functionalities. After listening to the recording, the user could walk around the scene and move the sound source in the sound field and understand sound spatialisation. They could also apply different materials to the sound field and gather more information about materials’ absorption coefficients. Meanwhile, the second phase was to accomplish the creation of customisable environments, by showing the user what parameters were used in order to create the first scene. However, this scene gave them more freedom to assign a different material to each wall, floor and ceiling to the enclosed room. Upon selecting these materials, the user could listen to a sound recording that would explain how to maximise the reflection of sound in different corners of the room. By giving instructions on which materials to apply to each side of the room, the user is able to distinguish highly absorbent from highly reflective material coefficients. And, finally, the third phase is formed by two different scenes. Each of these environments aimed to simplify two complex concepts and increase awareness to other subtleties in sound theory. The first task was to understand the effect of Occlusion and Directivity Patterns, by listening to two equal sound sources and the influence that an extra one would have on the way sound reflects on different objects. The second task was to find a mermaid in a pitch-black cave by following an approximate animation of the mermaid’s late reflections in that sound field. 

'Think aloud' method was used to record users comments while accomplishing a task 

After completing the VR-Headset-related tasks, participants had to complete a 7 question questionnaire:
Questionnaire: Sound Spatialisation Techniques and Artificial Reverberation in WebVR


1.	The sound that you have just listened to. Did it sound like it was in a room made of:

    a.	Metal

    b.	Transparent(no effects applied)

    c.	Curtains(carpet-like)

    d.	Grass

2.	The sound that you have just listened to. Did it sound like it was in a room made of:

    a.	Curtains(carpet-like)

    b.	Marble

    c.	Transparent(no effects applied)

    d.	Sheet of rocks

3.	If it ever came to work on a game that required heavy thinking on sound spatialisation techniques in Virtual Reality, do you feel that you could support the developers team and other services after using this WebVR tool?

    a.	Yes, definitely

    b.	Maybe I could do some reading, but I would understand the bigger picture

    c.	This tool would only serve as an initial understanding. I would not use it again

    d.	No

4.	What was the main purpose of the second scene – the customisable scene?

    a.	It was just to play around and create my own environment

    b.	To create surreal environments that would not be able to experience in reality

    c.	To showcase the power of the Resonance Audio SDK 

    d.	I don’t know. Didn’t quite get the purpose of it

5.	Could you remind me of what occlusion and directivity patterns are? Select more than one.   

    a.	The sound coming from the sphere and 3D models would come originally from only on direction, but the configuration of their directivity pattern made them propagate in all directions.

    b.	The sound coming from the sphere and 3D models would come originally from all directions, but the configuration of their directivity pattern made them propagate from a desired direction.

    c.	They help you understand how sound sources interact with objects surrounding them. The higher the number of sources in a sound field, the louder they will sound!

    d.	They help you understand how sound sources interact with objects surrounding them. Increasing the number of sources will make each object less identifiable. 

6.	What are/is the way(s) that sound arrives our human ears?

    a.	Proximate sound, early reflections, late reflections.

    b.	Direct sound and total reflections.

    c.	Direct sound, early and late reflections.

    d.	Direct sound. 

7.	The measurement that best sonically describes the soundfield that you are placed in, in terms of reverberation is:

    a.	Direct sound.

    b.	Durations of late reflections in 9 centre frequency bands.

    c.	The materials that the   room is made of.

    d.	The musical properties of the sound source. 



## Supervisor Meeting Notes 
Really consider what is my user groups or what is my user selection criteria 

 - game designers
 - front end developers
 - graphic designers
 - digital marketeers
  
Thought about alternative usage of the application

Read more about RT60, the Web Audio API, RA and sabine and eyring functions
